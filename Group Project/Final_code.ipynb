{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jcvdm01/machine-and-deep-learning/blob/main/Group%20Project/Final_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "px5UOxil-2Ci"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from sklearn.ensemble import RandomForestClassifier as RFC\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "from scipy import stats\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint,uniform\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Import data and drop redundent variables\n",
        "df = pd.read_csv('lending_club_loan_two.csv')\n",
        "df = df.drop(['grade', 'emp_title', 'title', 'installment', 'issue_d', 'earliest_cr_line', 'emp_length'], axis=1)\n",
        "\n",
        "# Generate dummies for categorial variables\n",
        "dummies = ['sub_grade', 'verification_status', 'purpose',\n",
        "            'initial_list_status', 'application_type', 'home_ownership']\n",
        "df = pd.get_dummies(df, columns=dummies, drop_first=True)\n",
        "\n",
        "# Extract Zip code from Address and remove Address\n",
        "df['zip_code'] = df.address.apply(lambda x: x[-5:])\n",
        "df = pd.get_dummies(df, columns=['zip_code'], drop_first=True)\n",
        "df.drop('address', axis=1, inplace=True)\n",
        "\n",
        "# process term from string to int\n",
        "term_values = {' 36 months': 36, ' 60 months': 60}\n",
        "df['term'] = df.term.map(term_values)\n",
        "\n",
        "# dummy for dependent variable(loan status)\n",
        "df['loan_status_binary'] = df['loan_status'].apply(lambda x: 0 if x == 'Fully Paid' else 1)\n",
        "df = df.drop(['loan_status'], axis=1)\n",
        "\n",
        "\n",
        "# Fill nan total_acc by group averages\n",
        "total_acc_avg = df.groupby(by='total_acc').mean().mort_acc\n",
        "def fill_mort_acc(total_acc, mort_acc):\n",
        "    if np.isnan(mort_acc):\n",
        "        return total_acc_avg[total_acc].round()\n",
        "    else:\n",
        "        return mort_acc\n",
        "df['mort_acc'] = df.apply(lambda x: fill_mort_acc(x['total_acc'], x['mort_acc']), axis=1)\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "y = df['loan_status_binary']\n",
        "X = df.drop('loan_status_binary', axis = 1)\n",
        "\n",
        "# Turn all booleans into floats (1 or 0)\n",
        "X = X.astype(float)\n",
        "\n",
        "#Split data 80/20\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Apply SMOTE on original df\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Apply PCA on original df\n",
        "pca = PCA(n_components=0.95)\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)\n",
        "\n",
        "# Apply pca on Smote\n",
        "pca_smote = PCA(n_components=0.95)\n",
        "X_train_smote_pca = pca_smote.fit_transform(X_train_smote)\n",
        "X_test_smote_pca = pca_smote.transform(X_test)\n",
        "y_train_smote_pca = y_train_smote\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KreAbS1-2Ck",
        "outputId": "44d7fcce-6c92-41c6-e313-81383f90a06b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 60 candidates, totalling 180 fits\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[32m     36\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mClassification Report (Test Set):\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     37\u001b[39m     \u001b[38;5;28mprint\u001b[39m(classification_report(ytest, y_test_pred))\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m \u001b[43mCreateRandomForest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[32m     42\u001b[39m CreateRandomForest(X_train_pca, X_test_pca, y_train, y_test)\n\u001b[32m     43\u001b[39m CreateRandomForest(X_train_smote, X_test, y_train_smote, y_test)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mCreateRandomForest\u001b[39m\u001b[34m(Xtrain, Xtest, ytrain, ytest)\u001b[39m\n\u001b[32m     13\u001b[39m rf_search = RandomizedSearchCV(\n\u001b[32m     14\u001b[39m estimator=base_rf,\n\u001b[32m     15\u001b[39m param_distributions=param_grid,\n\u001b[32m   (...)\u001b[39m\u001b[32m     21\u001b[39m random_state=\u001b[32m42\u001b[39m\n\u001b[32m     22\u001b[39m )\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Fit search on training data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[43mrf_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mytrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m best_rf = rf_search.best_estimator_\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\basso\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\basso\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1018\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1019\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1020\u001b[39m     )\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1027\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1028\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\basso\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1951\u001b[39m, in \u001b[36mRandomizedSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1949\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1950\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1951\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1952\u001b[39m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1953\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[32m   1954\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1955\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\basso\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    962\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    963\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    964\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    965\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    966\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    967\u001b[39m         )\n\u001b[32m    968\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m970\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m    989\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    990\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    993\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\basso\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\basso\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2001\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2002\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2003\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2004\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2005\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2007\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\basso\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1647\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1649\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1650\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1652\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1653\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1654\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1655\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1656\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\basso\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs) == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m   1760\u001b[39m     (\u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(\n\u001b[32m   1761\u001b[39m         timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING)):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1763\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1765\u001b[39m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[32m   1766\u001b[39m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[32m   1767\u001b[39m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Function to build, tune, and evaluate a Random Forest on a given dataset\n",
        "def CreateRandomForest(Xtrain, Xtest, ytrain, ytest):\n",
        "    # Define the hyperparameter search space\n",
        "    param_grid = {\n",
        "        'n_estimators': stats.randint(100, 1500),       # Number of trees\n",
        "        'max_depth': stats.randint(10, 100),            # Maximum depth of each tree\n",
        "        'min_samples_split': stats.randint(2, 10),      # Minimum samples to split a node\n",
        "        'min_samples_leaf': stats.randint(1, 10)        # Minimum samples at a leaf node\n",
        "    }\n",
        "\n",
        "    # Initialize the base Random Forest model\n",
        "    base_rf = RFC(class_weight='balanced', random_state=42)\n",
        "    # class_weight='balanced' compensates for class imbalance (e.g., default vs non-default)\n",
        "\n",
        "    # Set up RandomizedSearchCV for hyperparameter tuning\n",
        "    rf_search = RandomizedSearchCV(\n",
        "        estimator=base_rf,\n",
        "        param_distributions=param_grid,\n",
        "        n_iter=60,                   # Number of hyperparameter combinations to try\n",
        "        cv=3,                        # 3-fold cross-validation\n",
        "        scoring='roc_auc',          # Optimize AUC (suitable for imbalanced binary classification)\n",
        "        n_jobs=2,                   # Use 2 CPU cores (limit to avoid memory overload)\n",
        "        verbose=1,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Fit the search on the training data\n",
        "    rf_search.fit(Xtrain, ytrain)\n",
        "\n",
        "    # Get the best model found by RandomizedSearchCV\n",
        "    best_rf = rf_search.best_estimator_\n",
        "\n",
        "    # Generate predictions on both training and testing data\n",
        "    y_train_pred = best_rf.predict(Xtrain)\n",
        "    y_test_pred = best_rf.predict(Xtest)\n",
        "\n",
        "    # Output the best parameters found\n",
        "    print(\"\\nBest Parameters:\", rf_search.best_params_)\n",
        "\n",
        "    # Print classification report on training set\n",
        "    print(\"Classification Report (Train Set):\")\n",
        "    print(classification_report(ytrain, y_train_pred, target_names=[\"Default\", \"Non-default\"]))\n",
        "\n",
        "    # Print classification report on test set\n",
        "    print(\"Classification Report (Test Set):\")\n",
        "    print(classification_report(ytest, y_test_pred, target_names=[\"Default\", \"Non-default\"]))\n",
        "\n",
        "\n",
        "# Apply the function on various dataset variants:\n",
        "# 1. Original dataset\n",
        "CreateRandomForest(X_train, X_test, y_train, y_test)\n",
        "\n",
        "# 2. PCA-transformed version of the original dataset\n",
        "CreateRandomForest(X_train_pca, X_test_pca, y_train, y_test)\n",
        "\n",
        "# 3. SMOTE-balanced dataset\n",
        "CreateRandomForest(X_train_smote, X_test, y_train_smote, y_test)\n",
        "\n",
        "# 4. SMOTE-balanced + PCA-transformed\n",
        "CreateRandomForest(X_train_smote_pca, X_test_smote_pca, y_train_smote_pca, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfz8LuwR-2Cl",
        "outputId": "0ad3867d-ba25-4d2d-b10d-98c82f141149"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 60 candidates, totalling 180 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\basso\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:05:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report (Train Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.82      0.88    254073\n",
            "           1       0.53      0.82      0.64     62102\n",
            "\n",
            "    accuracy                           0.82    316175\n",
            "   macro avg       0.74      0.82      0.76    316175\n",
            "weighted avg       0.87      0.82      0.83    316175\n",
            "\n",
            "Classification Report (Test Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.81      0.87     63623\n",
            "           1       0.51      0.80      0.62     15421\n",
            "\n",
            "    accuracy                           0.81     79044\n",
            "   macro avg       0.73      0.81      0.75     79044\n",
            "weighted avg       0.86      0.81      0.82     79044\n",
            "\n",
            "Fitting 3 folds for each of 60 candidates, totalling 180 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\basso\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:44:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report (Train Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.80      0.87    254073\n",
            "           1       0.50      0.82      0.62     62102\n",
            "\n",
            "    accuracy                           0.80    316175\n",
            "   macro avg       0.72      0.81      0.74    316175\n",
            "weighted avg       0.86      0.80      0.82    316175\n",
            "\n",
            "Classification Report (Test Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.79      0.86     63623\n",
            "           1       0.48      0.80      0.60     15421\n",
            "\n",
            "    accuracy                           0.79     79044\n",
            "   macro avg       0.71      0.80      0.73     79044\n",
            "weighted avg       0.85      0.79      0.81     79044\n",
            "\n",
            "Fitting 3 folds for each of 60 candidates, totalling 180 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\basso\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [02:36:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report (Train Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98    254073\n",
            "           1       1.00      0.96      0.98    254073\n",
            "\n",
            "    accuracy                           0.98    508146\n",
            "   macro avg       0.98      0.98      0.98    508146\n",
            "weighted avg       0.98      0.98      0.98    508146\n",
            "\n",
            "Classification Report (Test Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.98      0.93     63623\n",
            "           1       0.85      0.51      0.64     15421\n",
            "\n",
            "    accuracy                           0.89     79044\n",
            "   macro avg       0.87      0.74      0.79     79044\n",
            "weighted avg       0.88      0.89      0.88     79044\n",
            "\n",
            "Fitting 3 folds for each of 60 candidates, totalling 180 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\basso\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [03:27:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report (Train Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00    254073\n",
            "           1       0.99      1.00      1.00    254073\n",
            "\n",
            "    accuracy                           1.00    508146\n",
            "   macro avg       1.00      1.00      1.00    508146\n",
            "weighted avg       1.00      1.00      1.00    508146\n",
            "\n",
            "Classification Report (Test Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.87      0.89     63623\n",
            "           1       0.54      0.65      0.59     15421\n",
            "\n",
            "    accuracy                           0.83     79044\n",
            "   macro avg       0.73      0.76      0.74     79044\n",
            "weighted avg       0.84      0.83      0.83     79044\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# XGBoost with scale_pos_weight = 4 for imbalanced (original) data\n",
        "def CreateXGBoostUnbalanced(Xtrain, Xtest, ytrain, ytest):\n",
        "\n",
        "    # Define hyperparameter search space\n",
        "    param_dist = {\n",
        "        'n_estimators': randint(200, 800),\n",
        "        'max_depth': randint(3, 15),\n",
        "        'learning_rate': uniform(0, 1),\n",
        "        'subsample': uniform(0.6, 0.4),\n",
        "        'colsample_bytree': uniform(0.6, 0.4),\n",
        "        'gamma': uniform(0, 0.5)\n",
        "    }\n",
        "\n",
        "    # Initialize base XGBoost model with class imbalance compensation\n",
        "    xgb_clf = XGBClassifier(\n",
        "        objective='binary:logistic',\n",
        "        eval_metric='auc',\n",
        "        use_label_encoder=False,\n",
        "        scale_pos_weight=4  # Weighting for imbalanced classes\n",
        "    )\n",
        "\n",
        "    # Perform randomized search over hyperparameters with 3-fold CV\n",
        "    xgb_cv = RandomizedSearchCV(\n",
        "        xgb_clf,\n",
        "        param_distributions=param_dist,\n",
        "        n_iter=60,\n",
        "        cv=3,\n",
        "        scoring='roc_auc',\n",
        "        verbose=1,\n",
        "        n_jobs=2  # Limit CPU usage to avoid Windows OSError\n",
        "    )\n",
        "\n",
        "    # Train the model with the best parameter set found\n",
        "    xgb_cv.fit(Xtrain, ytrain)\n",
        "\n",
        "    # Retrieve the best fitted model\n",
        "    best_xgb = xgb_cv.best_estimator_\n",
        "\n",
        "    # Make predictions\n",
        "    y_train_pred_xgb = best_xgb.predict(Xtrain)\n",
        "    y_test_pred_xgb = best_xgb.predict(Xtest)\n",
        "\n",
        "    # Output evaluation metrics\n",
        "    print(\"Classification Report (Train Set):\")\n",
        "    print(classification_report(ytrain, y_train_pred_xgb))\n",
        "\n",
        "    print(\"Classification Report (Test Set):\")\n",
        "    print(classification_report(ytest, y_test_pred_xgb))\n",
        "\n",
        "\n",
        "# XGBoost without scale_pos_weight, for use on balanced data (e.g., SMOTE)\n",
        "def Create_XGBoost_Balanced(Xtrain, Xtest, ytrain, ytest):\n",
        "\n",
        "    # Define hyperparameter search space\n",
        "    param_dist = {\n",
        "        'n_estimators': randint(200, 800),\n",
        "        'max_depth': randint(3, 15),\n",
        "        'learning_rate': uniform(0, 1),\n",
        "        'subsample': uniform(0.6, 0.4),\n",
        "        'colsample_bytree': uniform(0.6, 0.4),\n",
        "        'gamma': uniform(0, 0.5)\n",
        "    }\n",
        "\n",
        "    # Initialize XGBoost classifier without class weighting\n",
        "    xgb_clf = XGBClassifier(\n",
        "        objective='binary:logistic',\n",
        "        eval_metric='auc',\n",
        "        use_label_encoder=False,\n",
        "    )\n",
        "\n",
        "    # Perform randomized hyperparameter search\n",
        "    xgb_cv = RandomizedSearchCV(\n",
        "        xgb_clf,\n",
        "        param_distributions=param_dist,\n",
        "        n_iter=60,\n",
        "        cv=3,\n",
        "        scoring='roc_auc',\n",
        "        verbose=1,\n",
        "        n_jobs=2\n",
        "    )\n",
        "\n",
        "    # Fit the randomized search to the training data\n",
        "    xgb_cv.fit(Xtrain, ytrain)\n",
        "\n",
        "    # Retrieve the best model found\n",
        "    best_xgb = xgb_cv.best_estimator_\n",
        "\n",
        "    # Generate predictions\n",
        "    y_train_pred_xgb = best_xgb.predict(Xtrain)\n",
        "    y_test_pred_xgb = best_xgb.predict(Xtest)\n",
        "\n",
        "    # Output evaluation metrics\n",
        "    print(\"Classification Report (Train Set):\")\n",
        "    print(classification_report(ytrain, y_train_pred_xgb))\n",
        "\n",
        "    print(\"Classification Report (Test Set):\")\n",
        "    print(classification_report(ytest, y_test_pred_xgb))\n",
        "\n",
        "\n",
        "# Run the function on different versions of the dataset\n",
        "CreateXGBoostUnbalanced(X_train, X_test, y_train, y_test)  # Original data\n",
        "CreateXGBoostUnbalanced(X_train_pca, X_test_pca, y_train, y_test)  # PCA-transformed original\n",
        "Create_XGBoost_Balanced(X_train_smote, X_test, y_train_smote, y_test)  # SMOTE-balanced\n",
        "Create_XGBoost_Balanced(X_train_smote_pca, X_test_smote_pca, y_train_smote_pca, y_test)  # SMOTE + PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRrcVfBo-2Cl",
        "outputId": "9a35e68d-18bd-4e84-9aba-63e301c8db58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8539 - loss: 0.3560 - precision_8: 0.8220 - val_accuracy: 0.8889 - val_loss: 0.2638 - val_precision_8: 0.9930\n",
            "Epoch 2/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8872 - loss: 0.2668 - precision_8: 0.9872 - val_accuracy: 0.8887 - val_loss: 0.2611 - val_precision_8: 0.9945\n",
            "Epoch 3/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8876 - loss: 0.2642 - precision_8: 0.9810 - val_accuracy: 0.8889 - val_loss: 0.2604 - val_precision_8: 0.9986\n",
            "Epoch 4/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8877 - loss: 0.2621 - precision_8: 0.9804 - val_accuracy: 0.8888 - val_loss: 0.2610 - val_precision_8: 0.9970\n",
            "Epoch 5/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8869 - loss: 0.2633 - precision_8: 0.9742 - val_accuracy: 0.8889 - val_loss: 0.2596 - val_precision_8: 0.9964\n",
            "Epoch 6/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8885 - loss: 0.2602 - precision_8: 0.9725 - val_accuracy: 0.8888 - val_loss: 0.2595 - val_precision_8: 0.9966\n",
            "Epoch 7/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8879 - loss: 0.2608 - precision_8: 0.9714 - val_accuracy: 0.8889 - val_loss: 0.2590 - val_precision_8: 0.9949\n",
            "Epoch 8/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8883 - loss: 0.2602 - precision_8: 0.9700 - val_accuracy: 0.8889 - val_loss: 0.2597 - val_precision_8: 0.9923\n",
            "Epoch 9/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8883 - loss: 0.2600 - precision_8: 0.9657 - val_accuracy: 0.8891 - val_loss: 0.2592 - val_precision_8: 0.9841\n",
            "Epoch 10/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8879 - loss: 0.2605 - precision_8: 0.9612 - val_accuracy: 0.8888 - val_loss: 0.2591 - val_precision_8: 0.9923\n",
            "Epoch 11/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8877 - loss: 0.2599 - precision_8: 0.9615 - val_accuracy: 0.8890 - val_loss: 0.2598 - val_precision_8: 0.9780\n",
            "Epoch 12/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8879 - loss: 0.2604 - precision_8: 0.9650 - val_accuracy: 0.8888 - val_loss: 0.2589 - val_precision_8: 0.9636\n",
            "Epoch 13/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8886 - loss: 0.2582 - precision_8: 0.9520 - val_accuracy: 0.8887 - val_loss: 0.2591 - val_precision_8: 0.9669\n",
            "Epoch 14/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8888 - loss: 0.2586 - precision_8: 0.9587 - val_accuracy: 0.8891 - val_loss: 0.2589 - val_precision_8: 0.9631\n",
            "Epoch 15/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8883 - loss: 0.2588 - precision_8: 0.9555 - val_accuracy: 0.8890 - val_loss: 0.2584 - val_precision_8: 0.9646\n",
            "Epoch 16/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8885 - loss: 0.2584 - precision_8: 0.9576 - val_accuracy: 0.8890 - val_loss: 0.2587 - val_precision_8: 0.9706\n",
            "Epoch 17/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8899 - loss: 0.2562 - precision_8: 0.9532 - val_accuracy: 0.8890 - val_loss: 0.2590 - val_precision_8: 0.9791\n",
            "Epoch 18/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8885 - loss: 0.2582 - precision_8: 0.9559 - val_accuracy: 0.8891 - val_loss: 0.2590 - val_precision_8: 0.9591\n",
            "Epoch 19/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8885 - loss: 0.2583 - precision_8: 0.9590 - val_accuracy: 0.8889 - val_loss: 0.2587 - val_precision_8: 0.9754\n",
            "Epoch 20/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8896 - loss: 0.2560 - precision_8: 0.9505 - val_accuracy: 0.8889 - val_loss: 0.2592 - val_precision_8: 0.9776\n",
            "Epoch 21/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8885 - loss: 0.2582 - precision_8: 0.9540 - val_accuracy: 0.8889 - val_loss: 0.2594 - val_precision_8: 0.9782\n",
            "Epoch 22/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8901 - loss: 0.2560 - precision_8: 0.9535 - val_accuracy: 0.8887 - val_loss: 0.2588 - val_precision_8: 0.9815\n",
            "Epoch 23/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8889 - loss: 0.2573 - precision_8: 0.9518 - val_accuracy: 0.8888 - val_loss: 0.2589 - val_precision_8: 0.9743\n",
            "Epoch 24/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8889 - loss: 0.2575 - precision_8: 0.9551 - val_accuracy: 0.8890 - val_loss: 0.2593 - val_precision_8: 0.9770\n",
            "Epoch 25/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8892 - loss: 0.2566 - precision_8: 0.9502 - val_accuracy: 0.8888 - val_loss: 0.2591 - val_precision_8: 0.9601\n",
            "\u001b[1m2471/2471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 943us/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.94     63623\n",
            "           1       0.96      0.45      0.61     15421\n",
            "\n",
            "    accuracy                           0.89     79044\n",
            "   macro avg       0.92      0.72      0.77     79044\n",
            "weighted avg       0.90      0.89      0.87     79044\n",
            "\n",
            "Epoch 1/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8513 - loss: 0.3688 - precision_9: 0.8106 - val_accuracy: 0.8889 - val_loss: 0.2632 - val_precision_9: 1.0000\n",
            "Epoch 2/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8876 - loss: 0.2675 - precision_9: 0.9909 - val_accuracy: 0.8889 - val_loss: 0.2617 - val_precision_9: 1.0000\n",
            "Epoch 3/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8861 - loss: 0.2671 - precision_9: 0.9921 - val_accuracy: 0.8889 - val_loss: 0.2614 - val_precision_9: 1.0000\n",
            "Epoch 4/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8870 - loss: 0.2647 - precision_9: 0.9924 - val_accuracy: 0.8889 - val_loss: 0.2612 - val_precision_9: 1.0000\n",
            "Epoch 5/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8883 - loss: 0.2624 - precision_9: 0.9918 - val_accuracy: 0.8889 - val_loss: 0.2614 - val_precision_9: 1.0000\n",
            "Epoch 6/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8885 - loss: 0.2628 - precision_9: 0.9917 - val_accuracy: 0.8889 - val_loss: 0.2612 - val_precision_9: 1.0000\n",
            "Epoch 7/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8884 - loss: 0.2621 - precision_9: 0.9795 - val_accuracy: 0.8889 - val_loss: 0.2617 - val_precision_9: 1.0000\n",
            "Epoch 8/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8877 - loss: 0.2627 - precision_9: 0.9827 - val_accuracy: 0.8889 - val_loss: 0.2610 - val_precision_9: 1.0000\n",
            "Epoch 9/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8874 - loss: 0.2626 - precision_9: 0.9754 - val_accuracy: 0.8889 - val_loss: 0.2608 - val_precision_9: 0.9998\n",
            "Epoch 10/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8881 - loss: 0.2611 - precision_9: 0.9748 - val_accuracy: 0.8887 - val_loss: 0.2608 - val_precision_9: 0.9946\n",
            "Epoch 11/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8889 - loss: 0.2611 - precision_9: 0.9733 - val_accuracy: 0.8889 - val_loss: 0.2609 - val_precision_9: 0.9991\n",
            "Epoch 12/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8874 - loss: 0.2616 - precision_9: 0.9671 - val_accuracy: 0.8889 - val_loss: 0.2609 - val_precision_9: 0.9995\n",
            "Epoch 13/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8879 - loss: 0.2613 - precision_9: 0.9734 - val_accuracy: 0.8889 - val_loss: 0.2609 - val_precision_9: 0.9997\n",
            "Epoch 14/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8880 - loss: 0.2616 - precision_9: 0.9702 - val_accuracy: 0.8889 - val_loss: 0.2608 - val_precision_9: 0.9998\n",
            "Epoch 15/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8875 - loss: 0.2623 - precision_9: 0.9658 - val_accuracy: 0.8889 - val_loss: 0.2608 - val_precision_9: 1.0000\n",
            "Epoch 16/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8886 - loss: 0.2601 - precision_9: 0.9711 - val_accuracy: 0.8889 - val_loss: 0.2608 - val_precision_9: 1.0000\n",
            "Epoch 17/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8883 - loss: 0.2606 - precision_9: 0.9708 - val_accuracy: 0.8888 - val_loss: 0.2609 - val_precision_9: 0.9967\n",
            "Epoch 18/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8878 - loss: 0.2613 - precision_9: 0.9628 - val_accuracy: 0.8889 - val_loss: 0.2609 - val_precision_9: 0.9995\n",
            "Epoch 19/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8877 - loss: 0.2610 - precision_9: 0.9680 - val_accuracy: 0.8889 - val_loss: 0.2607 - val_precision_9: 1.0000\n",
            "Epoch 20/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8885 - loss: 0.2603 - precision_9: 0.9670 - val_accuracy: 0.8889 - val_loss: 0.2606 - val_precision_9: 0.9994\n",
            "Epoch 21/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8869 - loss: 0.2621 - precision_9: 0.9546 - val_accuracy: 0.8889 - val_loss: 0.2608 - val_precision_9: 1.0000\n",
            "Epoch 22/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8880 - loss: 0.2605 - precision_9: 0.9658 - val_accuracy: 0.8889 - val_loss: 0.2608 - val_precision_9: 0.9997\n",
            "Epoch 23/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8873 - loss: 0.2613 - precision_9: 0.9615 - val_accuracy: 0.8889 - val_loss: 0.2608 - val_precision_9: 0.9995\n",
            "Epoch 24/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8869 - loss: 0.2629 - precision_9: 0.9581 - val_accuracy: 0.8889 - val_loss: 0.2609 - val_precision_9: 1.0000\n",
            "Epoch 25/25\n",
            "\u001b[1m1236/1236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8877 - loss: 0.2604 - precision_9: 0.9667 - val_accuracy: 0.8889 - val_loss: 0.2608 - val_precision_9: 1.0000\n",
            "\u001b[1m2471/2471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 766us/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.94     63623\n",
            "           1       1.00      0.43      0.60     15421\n",
            "\n",
            "    accuracy                           0.89     79044\n",
            "   macro avg       0.94      0.72      0.77     79044\n",
            "weighted avg       0.90      0.89      0.87     79044\n",
            "\n",
            "Epoch 1/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7614 - loss: 0.4324 - precision_10: 0.7607 - val_accuracy: 0.7994 - val_loss: 0.3497 - val_precision_10: 0.4912\n",
            "Epoch 2/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7994 - loss: 0.3603 - precision_10: 0.7921 - val_accuracy: 0.7848 - val_loss: 0.3645 - val_precision_10: 0.4702\n",
            "Epoch 3/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8018 - loss: 0.3570 - precision_10: 0.7940 - val_accuracy: 0.7985 - val_loss: 0.3562 - val_precision_10: 0.4899\n",
            "Epoch 4/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8057 - loss: 0.3524 - precision_10: 0.7980 - val_accuracy: 0.7964 - val_loss: 0.3599 - val_precision_10: 0.4866\n",
            "Epoch 5/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8083 - loss: 0.3493 - precision_10: 0.8029 - val_accuracy: 0.7965 - val_loss: 0.3528 - val_precision_10: 0.4868\n",
            "Epoch 6/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8107 - loss: 0.3469 - precision_10: 0.8034 - val_accuracy: 0.8158 - val_loss: 0.3417 - val_precision_10: 0.5193\n",
            "Epoch 7/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8128 - loss: 0.3458 - precision_10: 0.8092 - val_accuracy: 0.7834 - val_loss: 0.3635 - val_precision_10: 0.4684\n",
            "Epoch 8/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8133 - loss: 0.3448 - precision_10: 0.8069 - val_accuracy: 0.8027 - val_loss: 0.3538 - val_precision_10: 0.4964\n",
            "Epoch 9/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8147 - loss: 0.3428 - precision_10: 0.8097 - val_accuracy: 0.8028 - val_loss: 0.3512 - val_precision_10: 0.4966\n",
            "Epoch 10/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8169 - loss: 0.3406 - precision_10: 0.8123 - val_accuracy: 0.8032 - val_loss: 0.3481 - val_precision_10: 0.4972\n",
            "Epoch 11/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8188 - loss: 0.3390 - precision_10: 0.8137 - val_accuracy: 0.8268 - val_loss: 0.3332 - val_precision_10: 0.5414\n",
            "Epoch 12/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8181 - loss: 0.3394 - precision_10: 0.8158 - val_accuracy: 0.8161 - val_loss: 0.3442 - val_precision_10: 0.5198\n",
            "Epoch 13/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8199 - loss: 0.3372 - precision_10: 0.8174 - val_accuracy: 0.8092 - val_loss: 0.3498 - val_precision_10: 0.5073\n",
            "Epoch 14/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8223 - loss: 0.3345 - precision_10: 0.8190 - val_accuracy: 0.8137 - val_loss: 0.3391 - val_precision_10: 0.5153\n",
            "Epoch 15/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8236 - loss: 0.3339 - precision_10: 0.8207 - val_accuracy: 0.8023 - val_loss: 0.3475 - val_precision_10: 0.4957\n",
            "Epoch 16/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8236 - loss: 0.3328 - precision_10: 0.8208 - val_accuracy: 0.7950 - val_loss: 0.3535 - val_precision_10: 0.4844\n",
            "Epoch 17/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8251 - loss: 0.3309 - precision_10: 0.8215 - val_accuracy: 0.8046 - val_loss: 0.3544 - val_precision_10: 0.4995\n",
            "Epoch 18/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8255 - loss: 0.3308 - precision_10: 0.8255 - val_accuracy: 0.7957 - val_loss: 0.3550 - val_precision_10: 0.4853\n",
            "Epoch 19/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8261 - loss: 0.3297 - precision_10: 0.8261 - val_accuracy: 0.8141 - val_loss: 0.3378 - val_precision_10: 0.5162\n",
            "Epoch 20/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8275 - loss: 0.3270 - precision_10: 0.8271 - val_accuracy: 0.8107 - val_loss: 0.3426 - val_precision_10: 0.5099\n",
            "Epoch 21/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8283 - loss: 0.3269 - precision_10: 0.8281 - val_accuracy: 0.7896 - val_loss: 0.3554 - val_precision_10: 0.4765\n",
            "Epoch 22/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8282 - loss: 0.3271 - precision_10: 0.8269 - val_accuracy: 0.8058 - val_loss: 0.3451 - val_precision_10: 0.5015\n",
            "Epoch 23/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8289 - loss: 0.3244 - precision_10: 0.8292 - val_accuracy: 0.8053 - val_loss: 0.3427 - val_precision_10: 0.5007\n",
            "Epoch 24/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8293 - loss: 0.3246 - precision_10: 0.8299 - val_accuracy: 0.8182 - val_loss: 0.3354 - val_precision_10: 0.5238\n",
            "Epoch 25/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8303 - loss: 0.3236 - precision_10: 0.8316 - val_accuracy: 0.8109 - val_loss: 0.3412 - val_precision_10: 0.5104\n",
            "\u001b[1m2471/2471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 879us/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.82      0.88     63623\n",
            "           1       0.51      0.76      0.61     15421\n",
            "\n",
            "    accuracy                           0.81     79044\n",
            "   macro avg       0.72      0.79      0.74     79044\n",
            "weighted avg       0.85      0.81      0.82     79044\n",
            "\n",
            "Epoch 1/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7564 - loss: 0.4364 - precision_11: 0.7623 - val_accuracy: 0.7877 - val_loss: 0.3769 - val_precision_11: 0.4741\n",
            "Epoch 2/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7980 - loss: 0.3628 - precision_11: 0.7958 - val_accuracy: 0.7868 - val_loss: 0.3648 - val_precision_11: 0.4728\n",
            "Epoch 3/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8001 - loss: 0.3602 - precision_11: 0.7958 - val_accuracy: 0.7825 - val_loss: 0.3691 - val_precision_11: 0.4669\n",
            "Epoch 4/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8021 - loss: 0.3582 - precision_11: 0.7968 - val_accuracy: 0.7826 - val_loss: 0.3672 - val_precision_11: 0.4670\n",
            "Epoch 5/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8026 - loss: 0.3567 - precision_11: 0.7958 - val_accuracy: 0.7958 - val_loss: 0.3560 - val_precision_11: 0.4857\n",
            "Epoch 6/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8030 - loss: 0.3566 - precision_11: 0.7975 - val_accuracy: 0.7896 - val_loss: 0.3591 - val_precision_11: 0.4765\n",
            "Epoch 7/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8035 - loss: 0.3555 - precision_11: 0.7975 - val_accuracy: 0.7854 - val_loss: 0.3636 - val_precision_11: 0.4707\n",
            "Epoch 8/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8047 - loss: 0.3541 - precision_11: 0.7995 - val_accuracy: 0.7862 - val_loss: 0.3652 - val_precision_11: 0.4717\n",
            "Epoch 9/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8059 - loss: 0.3523 - precision_11: 0.8031 - val_accuracy: 0.7834 - val_loss: 0.3672 - val_precision_11: 0.4680\n",
            "Epoch 10/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8055 - loss: 0.3532 - precision_11: 0.7986 - val_accuracy: 0.8021 - val_loss: 0.3489 - val_precision_11: 0.4954\n",
            "Epoch 11/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8078 - loss: 0.3513 - precision_11: 0.8036 - val_accuracy: 0.7902 - val_loss: 0.3586 - val_precision_11: 0.4774\n",
            "Epoch 12/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8081 - loss: 0.3497 - precision_11: 0.8014 - val_accuracy: 0.8033 - val_loss: 0.3559 - val_precision_11: 0.4973\n",
            "Epoch 13/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8085 - loss: 0.3492 - precision_11: 0.8036 - val_accuracy: 0.7956 - val_loss: 0.3520 - val_precision_11: 0.4852\n",
            "Epoch 14/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8087 - loss: 0.3499 - precision_11: 0.8028 - val_accuracy: 0.7972 - val_loss: 0.3544 - val_precision_11: 0.4877\n",
            "Epoch 15/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8088 - loss: 0.3489 - precision_11: 0.8055 - val_accuracy: 0.7994 - val_loss: 0.3509 - val_precision_11: 0.4912\n",
            "Epoch 16/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8105 - loss: 0.3468 - precision_11: 0.8085 - val_accuracy: 0.8071 - val_loss: 0.3479 - val_precision_11: 0.5037\n",
            "Epoch 17/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8114 - loss: 0.3459 - precision_11: 0.8092 - val_accuracy: 0.7929 - val_loss: 0.3602 - val_precision_11: 0.4813\n",
            "Epoch 18/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8120 - loss: 0.3459 - precision_11: 0.8083 - val_accuracy: 0.8087 - val_loss: 0.3458 - val_precision_11: 0.5064\n",
            "Epoch 19/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8127 - loss: 0.3453 - precision_11: 0.8109 - val_accuracy: 0.8073 - val_loss: 0.3475 - val_precision_11: 0.5040\n",
            "Epoch 20/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8125 - loss: 0.3441 - precision_11: 0.8113 - val_accuracy: 0.8061 - val_loss: 0.3553 - val_precision_11: 0.5021\n",
            "Epoch 21/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8129 - loss: 0.3439 - precision_11: 0.8125 - val_accuracy: 0.8064 - val_loss: 0.3470 - val_precision_11: 0.5025\n",
            "Epoch 22/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8139 - loss: 0.3430 - precision_11: 0.8109 - val_accuracy: 0.8010 - val_loss: 0.3519 - val_precision_11: 0.4936\n",
            "Epoch 23/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8149 - loss: 0.3418 - precision_11: 0.8129 - val_accuracy: 0.7916 - val_loss: 0.3612 - val_precision_11: 0.4794\n",
            "Epoch 24/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8145 - loss: 0.3424 - precision_11: 0.8127 - val_accuracy: 0.8005 - val_loss: 0.3523 - val_precision_11: 0.4929\n",
            "Epoch 25/25\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8147 - loss: 0.3404 - precision_11: 0.8124 - val_accuracy: 0.8112 - val_loss: 0.3443 - val_precision_11: 0.5109\n",
            "\u001b[1m2471/2471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 971us/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.82      0.88     63623\n",
            "           1       0.51      0.76      0.61     15421\n",
            "\n",
            "    accuracy                           0.81     79044\n",
            "   macro avg       0.72      0.79      0.74     79044\n",
            "weighted avg       0.85      0.81      0.82     79044\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.metrics import Precision\n",
        "\n",
        "def CreateSequential(Xtrain, Xtest, ytrain, ytest):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(78, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(39, activation= 'relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(19, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "\n",
        "    model.compile(loss = \"binary_crossentropy\", optimizer = 'adam', metrics =['accuracy', Precision()])\n",
        "    model.fit(x = Xtrain, y = ytrain, epochs = 25, batch_size = 256, validation_data = (Xtest, ytest))\n",
        "\n",
        "    predictions = (model.predict(Xtest) > 0.5).astype('int64')\n",
        "    print(classification_report(ytest, predictions))\n",
        "\n",
        "CreateSequential(X_train, X_test, y_train, y_test)\n",
        "CreateSequential(X_train_pca, X_test_pca, y_train, y_test)\n",
        "CreateSequential(X_train_smote, X_test, y_train_smote, y_test)\n",
        "CreateSequential(X_train_smote_pca, X_test_smote_pca, y_train_smote_pca, y_test)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8zJT2Sc-2Cm",
        "outputId": "4e4565d0-67cb-4fb3-e0b6-3396423b4b9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "117283    0\n",
            "151256    0\n",
            "242452    0\n",
            "273157    0\n",
            "213735    0\n",
            "         ..\n",
            "259721    0\n",
            "366594    1\n",
            "132193    1\n",
            "147164    0\n",
            "122200    0\n",
            "Name: loan_status_binary, Length: 316175, dtype: int64\n",
            "251650    1\n",
            "161400    0\n",
            "365051    0\n",
            "27512     0\n",
            "263208    0\n",
            "         ..\n",
            "32032     0\n",
            "289601    0\n",
            "172764    0\n",
            "102050    1\n",
            "73147     0\n",
            "Name: loan_status_binary, Length: 79044, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(y_train)\n",
        "print(y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMWoDUHZ-2Cm",
        "outputId": "b76fa575-f264-4a42-9418-9de2e20f2c58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(395219, 78)\n"
          ]
        }
      ],
      "source": [
        "print(X.shape)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}